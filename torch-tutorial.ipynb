{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef99f8f6-57b2-49c5-9ee2-4efe8d44da8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import struct\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652aba3f-890e-4831-87d9-64c26118321b",
   "metadata": {},
   "source": [
    "### Reading MNIST data (crash course)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33194952-6451-4322-8ad8-7593b3e63609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\x00\\x00\\x08\\x03'\n",
      "b'\\x00\\x00\\xea`'\n",
      "b'\\x00\\x00\\x00\\x1c'\n",
      "b'\\x00\\x00\\x00\\x1c'\n",
      "b'\\x00\\x00\\x00\\x00'\n",
      "b'\\x00\\x00\\x00\\x00'\n"
     ]
    }
   ],
   "source": [
    "with gzip.open('./data/train-images-idx3-ubyte.gz','rb') as f:\n",
    "    print(f.read(4))\n",
    "    print(f.read(4))\n",
    "    print(f.read(4))\n",
    "    print(f.read(4))\n",
    "    print(f.read(4))\n",
    "    print(f.read(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134a66bd-0fff-4f4c-a143-c02f03a0b9cb",
   "metadata": {},
   "source": [
    "8 bits in 1 byte (value ranges from 0-255).  \n",
    "Most people use hexadecimal (base 16) to represent bytes since it's more compact and divides evenly.  \n",
    "The values 0-255 in hexdecimal is 0x00 - 0xFF.  \n",
    "So each byte (== 8 bits) is represented by two hexadecimals digits.\n",
    "\n",
    "The following structure below represents the training set for MNIST. \n",
    "\n",
    "```r\n",
    "[offset] [type]          [value]          [description]\n",
    "0000     32 bit integer  0x00000803(2051) magic number\n",
    "0004     32 bit integer  60000            number of images\n",
    "0008     32 bit integer  28               number of rows\n",
    "0012     32 bit integer  28               number of columns\n",
    "0016     unsigned byte   ??               pixel\n",
    "0017     unsigned byte   ??               pixel\n",
    "........\n",
    "xxxx     unsigned byte   ??               pixel\n",
    "```\n",
    "\n",
    "Basically, the data starts on the 16th byte and everything before that is metadata.  \n",
    "We show below how to read this.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c54b466-9fe5-4c51-8607-c907c13cd4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/39969045/parsing-yann-lecuns-mnist-idx-file-format\n",
    "# http://yann.lecun.com/exdb/mnist/\n",
    "\n",
    "with gzip.open('./data/train-images-idx3-ubyte.gz','rb') as f:\n",
    "    magic, size = struct.unpack(\">II\", f.read(8))\n",
    "    nrows, ncols = struct.unpack(\">II\", f.read(8))\n",
    "    X_train = np.frombuffer(f.read(), dtype=np.dtype(np.uint8).newbyteorder('>'))\n",
    "    X_train = X_train.reshape((size, nrows, ncols))\n",
    "\n",
    "with gzip.open('./data/train-labels-idx1-ubyte.gz','rb') as f:\n",
    "    magic, size = struct.unpack(\">II\", f.read(8))\n",
    "    y_train = np.frombuffer(f.read(), dtype=np.dtype(np.uint8).newbyteorder('>'))\n",
    "    \n",
    "with gzip.open('./data/t10k-images-idx3-ubyte.gz','rb') as f:\n",
    "    magic, size = struct.unpack(\">II\", f.read(8))\n",
    "    nrows, ncols = struct.unpack(\">II\", f.read(8))\n",
    "    X_test = np.frombuffer(f.read(), dtype=np.dtype(np.uint8).newbyteorder('>'))\n",
    "    X_test = X_test.reshape((size, nrows, ncols))\n",
    "    \n",
    "with gzip.open('./data/t10k-labels-idx1-ubyte.gz','rb') as f:\n",
    "    magic, size = struct.unpack(\">II\", f.read(8))\n",
    "    y_test = np.frombuffer(f.read(), dtype=np.dtype(np.uint8).newbyteorder('>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201769cb-ec26-4e80-a4fb-1b20fa857588",
   "metadata": {},
   "source": [
    "[ChatGPT]\n",
    "\n",
    "In the given code snippet, the `struct.unpack` function is used to extract data from a binary file according to a specified format. The `struct` module in Python provides functions for working with C-style data structures represented as strings. It allows you to pack and unpack data in a binary format.\n",
    "\n",
    "Let's break down the usage of `struct.unpack` in the code:\n",
    "\n",
    "1. `magic, size = struct.unpack(\">II\", f.read(8))`\n",
    "   Here, `f.read(8)` reads 8 bytes from the file object `f`. The format string `\">II\"` specifies the format of the data to be unpacked. `\">\"` indicates big-endian byte order, and `I` represents an unsigned integer of size 4 bytes. Therefore, `struct.unpack(\">II\", f.read(8))` reads 8 bytes from the file, interprets the first 4 bytes as `magic` and the next 4 bytes as `size`, and assigns the unpacked values to the variables `magic` and `size`.\n",
    "\n",
    "2. `nrows, ncols = struct.unpack(\">II\", f.read(8))`\n",
    "   This line is similar to the previous one. It reads another 8 bytes from the file and interprets the first 4 bytes as `nrows` and the next 4 bytes as `ncols`.\n",
    "\n",
    "3. `data = np.frombuffer(f.read(), dtype=np.dtype(np.uint8).newbyteorder('>'))`\n",
    "   Here, `f.read()` reads the remaining data from the file. The `frombuffer` function from the NumPy library is used to create an array from the binary data. The data type is specified as `np.uint8`, representing an 8-bit unsigned integer. The `newbyteorder('>')` method is used to ensure the data is interpreted in big-endian byte order.\n",
    "\n",
    "4. `data = data.reshape((size, nrows, ncols))`\n",
    "   Finally, the `data` array is reshaped using the dimensions obtained from the previous unpacking steps. It is reshaped into a 3-dimensional array with `size` rows, `nrows` height, and `ncols` width."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2344ce33-2a76-4938-8aa5-caa2b848e760",
   "metadata": {},
   "source": [
    "[ChatGPT]\n",
    "\n",
    "There are two common types of endianness: big-endian and little-endian.\n",
    "\n",
    "Big-endian: In big-endian systems, the most significant byte (the byte containing the highest order bits) is stored at the lowest memory address, while the least significant byte is stored at the highest memory address. This means that the data is stored from left to right, with the most significant byte first.\n",
    "\n",
    "Little-endian: In little-endian systems, the least significant byte is stored at the lowest memory address, while the most significant byte is stored at the highest memory address. The data is stored from right to left, with the least significant byte first.\n",
    "\n",
    "To understand this concept, let's consider a 4-byte integer value 0x12345678. Here's how it would be stored in memory based on the endianness:\n",
    "\n",
    "Big-endian:\n",
    "\n",
    "Memory Address: 0x00 0x01 0x02 0x03\n",
    "Data Value: 0x12 0x34 0x56 0x78\n",
    "Little-endian:\n",
    "\n",
    "Memory Address: 0x00 0x01 0x02 0x03\n",
    "Data Value: 0x78 0x56 0x34 0x12\n",
    "\n",
    "Note that the endianness affects the ordering of bytes, but not the individual bits within each byte.\n",
    "\n",
    "Endianness is important when data is shared between systems or when reading data from a binary file format. It's essential to ensure that both the sender and receiver of data interpret the bytes in the correct order to avoid data corruption or misinterpretation. Most modern systems, including x86 and ARM processors, use little-endian architecture. However, big-endian systems are still in use, particularly in certain network protocols or older hardware architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9294a2dd-4a4e-4b54-ab1e-0ab0ed0f1984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask = np.random.uniform(low=0.0, high=1.0, size=len(y_train)) < .9\n",
    "\n",
    "# X_train_ = X_train[mask]\n",
    "# y_train_ = y_train[mask]\n",
    "\n",
    "# X_val = X_train[~mask]\n",
    "# y_val = y_train[~mask]\n",
    "\n",
    "# print(X_train_.shape, y_train_.shape)\n",
    "# print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7575508c-c342-49b3-835d-664c90a55d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_flattened = X_train.reshape(len(X_train), -1)\n",
    "X_test_flattened = X_test.reshape(len(X_test), -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a32787e-341b-489e-a2c4-463ddfe61379",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b3145ac-1ac1-4422-876d-c5ea8ff2722f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 21s\n",
      "Wall time: 1min 35s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SGDClassifier(loss=&#x27;log_loss&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier(loss=&#x27;log_loss&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SGDClassifier(loss='log_loss')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "classifier_sgd = SGDClassifier(loss='log_loss')\n",
    "classifier_sgd.fit(X_train_flattened, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd35e389-06ee-4f2d-bb6b-4369dd1ab06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96       958\n",
      "           1       0.97      0.98      0.97      1131\n",
      "           2       0.86      0.89      0.87       995\n",
      "           3       0.81      0.91      0.86       897\n",
      "           4       0.88      0.93      0.91       934\n",
      "           5       0.90      0.75      0.82      1075\n",
      "           6       0.94      0.91      0.93       989\n",
      "           7       0.86      0.96      0.91       916\n",
      "           8       0.87      0.70      0.78      1200\n",
      "           9       0.81      0.90      0.85       905\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.88     10000\n",
      "\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 44.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = classifier_sgd.predict(X_test_flattened)\n",
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732bb25e-6899-4c1c-918a-9c65f497f2ba",
   "metadata": {},
   "source": [
    "### XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b39b67a5-08ad-4c09-b2f5-5d46c340d5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 33min 17s\n",
      "Wall time: 2min 11s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              objective=&#x27;multi:softprob&#x27;, predictor=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              objective=&#x27;multi:softprob&#x27;, predictor=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              objective='multi:softprob', predictor=None, ...)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "classifier_xgb = XGBClassifier()\n",
    "classifier_xgb.fit(X_train_flattened, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3525f69b-94de-4318-928e-27e34560a3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98       993\n",
      "           1       0.99      0.99      0.99      1136\n",
      "           2       0.98      0.98      0.98      1033\n",
      "           3       0.98      0.98      0.98      1013\n",
      "           4       0.98      0.98      0.98       973\n",
      "           5       0.98      0.98      0.98       886\n",
      "           6       0.98      0.98      0.98       955\n",
      "           7       0.97      0.98      0.98      1023\n",
      "           8       0.98      0.98      0.98       972\n",
      "           9       0.97      0.97      0.97      1016\n",
      "\n",
      "    accuracy                           0.98     10000\n",
      "   macro avg       0.98      0.98      0.98     10000\n",
      "weighted avg       0.98      0.98      0.98     10000\n",
      "\n",
      "CPU times: total: 1.58 s\n",
      "Wall time: 86.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = classifier_xgb.predict(X_test_flattened)\n",
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989b7677-df93-4c4e-8890-74675c173652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explain f1\n",
    "# torch example (dataset, model, gpu, training loop); (conv)\n",
    "# explain relations\n",
    "# explain autograd and dag; similarity to sgd [make sgd example]\n",
    "# show adam optim\n",
    "# relu and activation functions\n",
    "# batch norm\n",
    "\n",
    "# monitor val loss (see sgd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
